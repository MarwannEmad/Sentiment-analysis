{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some details of the problem ... also mention the link of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add environment Packages paths to conda\n",
    "import os, sys\n",
    "# env_name = \"food_review\"\n",
    "# sys.path.append(f\"C:\\\\Environments\\\\{env_name}\\\\lib\\\\site-packages\\\\\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text preprocessing packages\n",
    "import nltk # Text libarary\n",
    "# nltk.download('stopwords')\n",
    "import string # Removing special characters {#, @, ...}\n",
    "import re as re # Regex Package\n",
    "from nltk.corpus import stopwords # Stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer # Stemmer & Lemmatizer\n",
    "from gensim.utils import simple_preprocess  # Text ==> List of Tokens\n",
    "\n",
    "# Text Embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Saving Model\n",
    "import pickle\n",
    "\n",
    "# Visualization Packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=1.3)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'568,454 Review'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{df.shape[0]:,} Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Text', 'Score']\n",
    "df_text = df[cols].copy()\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates\n",
    "Save the Cleaned data-frame also with the variable `df_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'393,579 Review'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.drop_duplicates('Text',inplace=True)\n",
    "df_text.reset_index(drop=True, inplace=True)\n",
    "f\"{df_text.shape[0]:,} Review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Pre-Processing\n",
    "`target` will be \n",
    " - 0 if score < 3 \n",
    " - 1 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text['target'] = [0 if i < 3 else 1 for i in df_text['Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target\n",
       "0  I have bought several of the Vitality canned d...      5       1\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1       0\n",
       "2  This is a confection that has been around a fe...      4       1\n",
       "3  If you are looking for the secret ingredient i...      2       0\n",
       "4  Great taffy at a great price.  There was a wid...      5       1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    336512\n",
       "0     57067\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Countplot for target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df_text['target']);\n",
    "plt.title('the count of target');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how such variance is huge ...   \n",
    "Then we need to down-sample such data ... by which both the positive and negative classes are balanced.\n",
    "\n",
    "### Balance Data Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from positive reviews Same number of negative reviews\n",
    "NEG_N = df_text.target.value_counts()[0]\n",
    "df_pos = df_text[df_text['target'] == 1]['Text'].sample(NEG_N, replace=False)\n",
    "df_text_balanced = pd.concat([df_text.iloc[df_pos.index], df_text[df_text.target == 0]]).reset_index()\n",
    "df_text_balanced.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PLot the target again after balancing\n",
    "## Write your code here\n",
    "sns.countplot(x=df_text_balanced['target']);\n",
    "plt.title('the count of target');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MarawanEmadAbdElHame\\AppData\\Roaming\\nltk_dat\n",
      "[nltk_data]     a...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MarawanEmadAbdElHame\\AppData\\Roaming\\nltk_dat\n",
      "[nltk_data]     a...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cleaning(strr):\n",
    "    strr = re.sub(\"\\\\<.*?\\\\>\", \"\", strr)  # Removing tags html from string\n",
    "    strr = re.sub(r\"http\\S+\", '', strr)  # Removing html links from string\n",
    "    strr = re.sub(r\"www\\S+\" , '', strr)  # Removing www links from string\n",
    "    strr = re.sub(\"&[a-z0-9]+|&#[0-9]{1,6}|&#x[0-9a-f]{1,6}\", '',strr) # Removing unrecognized words \n",
    "    strr = re.sub(\"\\\\s*\\\\b(?=\\\\w*(\\\\w)\\\\1{2,})\\\\w*\\\\b\",' ',strr) # Removing repeated character   \n",
    "    strr = re.sub(\"[^A-Za-z']+\", \" \", strr)   # Removing any brackets or special character or numbers \n",
    "    strr = re.sub(r'(Mr|Ms|Mrs)\\.?\\s[A-Z]\\w*', \" \", strr) # Removing names from strings \n",
    "    strr = \" \".join(strr.split()) # adjusting the spaces in string\n",
    "    return strr\n",
    "df_text_balanced['Text']= df_text_balanced['Text'].str.lower().str.strip()\n",
    "df_text_balanced['Text']= df_text_balanced['Text'].apply(Cleaning)\n",
    "df_text_balanced['Text']= df_text_balanced['Text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Updated_text(strr):\n",
    "    strr = re.sub(r\"won't\", \"will not\", strr)\n",
    "    strr = re.sub(r\"can\\'t\", \"can not\", strr)\n",
    "    strr = re.sub(r\"n\\'t\", \" not\", strr)\n",
    "    strr = re.sub(r\"\\'re\", \" are\", strr)\n",
    "    strr = re.sub(r\"\\'s\", \" is\", strr)\n",
    "    strr = re.sub(r\"\\'d\", \" would\", strr)\n",
    "    strr = re.sub(r\"\\'ll\", \" will\", strr)\n",
    "    strr = re.sub(r\"\\'t\", \" not\", strr)\n",
    "    strr = re.sub(r\"\\'ve\", \" have\", strr)\n",
    "    strr = re.sub(r\"\\'m\", \" am\", strr)\n",
    "    return strr\n",
    "df_text_balanced['Text']= df_text_balanced['Text'].apply(Updated_text)\n",
    "df_text_balanced['Text']= df_text_balanced['Text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i got the great taste that i was looking for w...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of course they are not really kimchi but who c...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i began drinking coffee only a couple years ag...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this tastes like regular tea mixed with vanill...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this oil is very good to cook with when heated...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target\n",
       "0  i got the great taste that i was looking for w...      4       1\n",
       "1  of course they are not really kimchi but who c...      5       1\n",
       "2  i began drinking coffee only a couple years ag...      5       1\n",
       "3  this tastes like regular tea mixed with vanill...      3       1\n",
       "4  this oil is very good to cook with when heated...      5       1"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('not')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWords(text):\n",
    "    x = ' '\n",
    "    lst=list()\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            lst.append(word)\n",
    "    return x.join(lst)\n",
    "df_text_balanced['Text']=df_text_balanced['Text'].apply(stopWords)\n",
    "#df_text_balanced['Text']=df_text_balanced['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>got great taste looking fruit gems arrived not...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>course not really kimchi cares like reconstitu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>began drinking coffee couple years ago tried t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tastes like regular tea mixed vanilla creamer ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil good cook heated low viscosity tends coat ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target\n",
       "0  got great taste looking fruit gems arrived not...      4       1\n",
       "1  course not really kimchi cares like reconstitu...      5       1\n",
       "2  began drinking coffee couple years ago tried t...      5       1\n",
       "3  tastes like regular tea mixed vanilla creamer ...      3       1\n",
       "4  oil good cook heated low viscosity tends coat ...      5       1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    x = ' '\n",
    "    ls = list()\n",
    "    for word in text.split():\n",
    "        ls.append(lemmatizer.lemmatize(word))\n",
    "    return x.join(ls)\n",
    "    \n",
    "df_text_balanced['Text'] = df_text_balanced['Text'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>got great taste looking fruit gem arrived not ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>course not really kimchi care like reconstitut...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>began drinking coffee couple year ago tried tw...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taste like regular tea mixed vanilla creamer p...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil good cook heated low viscosity tends coat ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target\n",
       "0  got great taste looking fruit gem arrived not ...      4       1\n",
       "1  course not really kimchi care like reconstitut...      5       1\n",
       "2  began drinking coffee couple year ago tried tw...      5       1\n",
       "3  taste like regular tea mixed vanilla creamer p...      3       1\n",
       "4  oil good cook heated low viscosity tends coat ...      5       1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    x = ' '\n",
    "    ls = list()\n",
    "    for word in text.split():\n",
    "        ls.append(stemmer.stem(word))\n",
    "    return x.join(ls)\n",
    "\n",
    "df_text_balanced['Text'] = df_text_balanced['Text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>got great tast look fruit gem arriv not easili...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cours not realli kimchi care like reconstitut ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>began drink coffe coupl year ago tri twenti di...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tast like regular tea mix vanilla creamer powd...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oil good cook heat low viscos tend coat pan fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  target\n",
       "0  got great tast look fruit gem arriv not easili...      4       1\n",
       "1  cours not realli kimchi care like reconstitut ...      5       1\n",
       "2  began drink coffe coupl year ago tri twenti di...      5       1\n",
       "3  tast like regular tea mix vanilla creamer powd...      3       1\n",
       "4  oil good cook heat low viscos tend coat pan fo...      5       1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Test & Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_text_balanced['Text']\n",
    "y = df_text_balanced['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embedding\n",
    " - Use `TfidfVectorizer`\n",
    " - `fit` on the training data only\n",
    " - `transform` on training and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF embedding for the Description\n",
    "vectorizer = TfidfVectorizer()\n",
    "# fit on training (such vectorizer will be saved for deployment)\n",
    "vectorizer_tfidf = vectorizer.fit(X)\n",
    "# transform on training data\n",
    "X_train = vectorizer_tfidf.transform(X_train)\n",
    "# transform on testing data\n",
    "X_test = vectorizer_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79893, 47127), (34241, 47127))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the dimensions of your data embeddings before entering to the model\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sklearn framework steps\n",
    " - init\n",
    " - fit\n",
    " - predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy = 84.52%\n"
     ]
    }
   ],
   "source": [
    "## initialize your Model\n",
    "clf = RandomForestClassifier(random_state=0) \n",
    "# Fit your Model on the Training Dataset\n",
    "clf.fit(X_train, y_train)\n",
    "# Predict on Test data\n",
    "preds = clf.predict(X_test)\n",
    "# Calculate Model Accuracy\n",
    "acc = accuracy_score(preds, y_test)\n",
    "print(f\"Model Accuracy = {round(acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Instance Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_test(review, model, vectorizer):\n",
    "    # Clean Review\n",
    "    review_c = Cleaning(review)\n",
    "    review_c = Updated_text(review_c)\n",
    "    review_c = stopWords(review_c)\n",
    "    review_c = lemmatization(review_c)\n",
    "    review_c = stemming(review_c)\n",
    "    # Embed review using tf-idf vectorizer\n",
    "    embedding = vectorizer.transform([review_c])\n",
    "    # Predict using your model\n",
    "    prediction =model.predict(embedding)\n",
    "    # Return the Sentiment Prediction\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_1 = \"That's a good Dish, Good Job\"\n",
    "review_2 = \"That's the worst Dish ever tasted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test(review_1, clf, vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test(review_2, clf, vectorizer_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "... ## Save model\n",
    "model_name = 'rf_model.pk'\n",
    "model_path = os.path.join('F:/Career Projects/', model_name)\n",
    "pickle.dump(clf, open(model_path, 'wb'))\n",
    "\n",
    "... ## Save tfidf-vectorizer\n",
    "vectorizer_name = 'tfidf_vectorizer.pk'\n",
    "vectorizer_path = os.path.join('F:/Career Projects/', vectorizer_name)\n",
    "pickle.dump(vectorizer, open(vectorizer_path, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model Again and test them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(model_path,'rb'))\n",
    "loaded_vect = pickle.load(open(vectorizer_path,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test(review_1, loaded_model, loaded_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test(review_2, loaded_model, loaded_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job !\n",
    "### Now Deploy your ML model using Streamlit Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyngrok\n",
    "\n",
    "!pip install -q streamlit\n",
    "\n",
    "!pip install -q streamlit_ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting project.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile project.py\n",
    "import pickle\n",
    "import streamlit as st\n",
    "import nltk # Text libarary\n",
    "# nltk.download('stopwords')\n",
    "import string # Removing special characters {#, @, ...}\n",
    "import re as re # Regex Package\n",
    "from nltk.corpus import stopwords # Stopwords\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer # Stemmer & Lemmatizer\n",
    "from gensim.utils import simple_preprocess  # Text ==> List of Tokens\n",
    "\n",
    "model_path = 'F:/Career Projects/rf_model.pk'\n",
    "vectorizer_path = 'F:/Career Projects/tfidf_vectorizer.pk'\n",
    "model = pickle.load(open(model_path,'rb'))\n",
    "vectorizer = pickle.load(open(vectorizer_path,'rb'))\n",
    "\n",
    "def Cleaning(strr):\n",
    "    strr = re.sub(\"\\\\<.*?\\\\>\", \"\", strr)  # Removing tags html from string\n",
    "    strr = re.sub(r\"http\\S+\", '', strr)  # Removing html links from string\n",
    "    strr = re.sub(r\"www\\S+\" , '', strr)  # Removing www links from string\n",
    "    strr = re.sub(\"&[a-z0-9]+|&#[0-9]{1,6}|&#x[0-9a-f]{1,6}\", '',strr) # Removing unrecognized words \n",
    "    strr = re.sub(\"\\\\s*\\\\b(?=\\\\w*(\\\\w)\\\\1{2,})\\\\w*\\\\b\",' ',strr) # Removing repeated character   \n",
    "    strr = re.sub(\"[^A-Za-z']+\", \" \", strr)   # Removing any brackets or special character or numbers \n",
    "    strr = re.sub(r'(Mr|Ms|Mrs)\\.?\\s[A-Z]\\w*', \" \", strr) # Removing names from strings \n",
    "    strr = \" \".join(strr.split()) # adjusting the spaces in string\n",
    "    return strr\n",
    "\n",
    "def Updated_text(strr):\n",
    "    strr = re.sub(r\"won't\", \"will not\", strr)\n",
    "    strr = re.sub(r\"can\\'t\", \"can not\", strr)\n",
    "    strr = re.sub(r\"n\\'t\", \" not\", strr)\n",
    "    strr = re.sub(r\"\\'re\", \" are\", strr)\n",
    "    strr = re.sub(r\"\\'s\", \" is\", strr)\n",
    "    strr = re.sub(r\"\\'d\", \" would\", strr)\n",
    "    strr = re.sub(r\"\\'ll\", \" will\", strr)\n",
    "    strr = re.sub(r\"\\'t\", \" not\", strr)\n",
    "    strr = re.sub(r\"\\'ve\", \" have\", strr)\n",
    "    strr = re.sub(r\"\\'m\", \" am\", strr)\n",
    "    return strr\n",
    "\n",
    "\n",
    "def stopWords(text):\n",
    "    x = ' '\n",
    "    lst=list()\n",
    "    for word in text.split():\n",
    "        if word not in stop_words:\n",
    "            lst.append(word)\n",
    "    return x.join(lst)\n",
    "    \n",
    "\n",
    "def lemmatization(text):\n",
    "    x = ' '\n",
    "    ls = list()\n",
    "    for word in text.split():\n",
    "        ls.append(lemmatizer.lemmatize(word))\n",
    "    return x.join(ls)\n",
    "\n",
    "\n",
    "def stemming(text):\n",
    "    x = ' '\n",
    "    ls = list()\n",
    "    for word in text.split():\n",
    "        ls.append(stemmer.stem(word))\n",
    "    return x.join(ls)\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('not')\n",
    "def prediction(review, model, vectorizer):\n",
    "    # Clean Review\n",
    "    review_c = Cleaning(review)\n",
    "    review_c = Updated_text(review_c)\n",
    "    review_c = stopWords(review_c)\n",
    "    review_c = lemmatization(review_c)\n",
    "    review_c = stemming(review_c)\n",
    "    # Embed review using tf-idf vectorizer\n",
    "    embedding = vectorizer.transform([review_c])\n",
    "    # Predict using your model\n",
    "    prediction =model.predict(embedding)\n",
    "    # Return the Sentiment Prediction\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\"\n",
    "\n",
    "def main() :\n",
    "    \n",
    "    primaryColor=\"\"\n",
    "    base=\"dark\"\n",
    "    from PIL import Image\n",
    "    img = Image.open(\"Amazone_image.png\")\n",
    "    st.image(img, use_column_width=True)\n",
    "    primaryColor=\"red\"\n",
    "    st.title('Amazon Food Review')\n",
    "    st.subheader(\"Analyze Your Text\")\n",
    "    text = st.text_area('Enter your Review',height=35)\n",
    "    if st.button('Analyse'):\n",
    "        pred= prediction(text,model,vectorizer)\n",
    "        if pred =='Positive':\n",
    "            return st.success(pred)\n",
    "        else :\n",
    "            return st.error(pred)\n",
    "\n",
    "\n",
    "if __name__=='__main__': \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run project.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NgrokTunnel: \"http://aeab-102-47-53-218.ngrok.io\" -> \"http://localhost:8501\">"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2021-08-26T22:33:54+0200 lvl=eror msg=\"heartbeat timeout, terminating session\" obj=csess id=5007074f572a clientid=7a08cb20c315fcc321e3acb6a1289dd8\n",
      "t=2021-08-26T22:33:54+0200 lvl=eror msg=\"session closed, starting reconnect loop\" obj=csess id=838cf9ce8a9f err=\"session closed\"\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "public_url = ngrok.connect('8501')\n",
    "public_url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: watchdog in c:\\users\\marawanemadabdelhame\\anaconda3\\lib\\site-packages (0.10.3)\n",
      "Requirement already satisfied: pathtools>=0.1.1 in c:\\users\\marawanemadabdelhame\\anaconda3\\lib\\site-packages (from watchdog) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install watchdog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
